{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ng = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y = ng.data, ng.target\n",
    "Xtrain, Xtest, Ctrain, Ctest = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = list(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates dictionary for a file, with words as keys, and tf value as values\n",
    "\n",
    "def tf(file):\n",
    "    file = file.split()\n",
    "    doc_dict = {}\n",
    "    for word in file:\n",
    "        word = word.lower()\n",
    "\n",
    "        for c in string.punctuation:\n",
    "            word = word.replace(c,\"\")\n",
    "    \n",
    "        if word not in stop:\n",
    "            if word in doc_dict:\n",
    "                doc_dict[word] = doc_dict[word] + 1\n",
    "            else:\n",
    "                doc_dict[word] = 1\n",
    "    \n",
    "    #normalizing the dictionary\n",
    "    length = float(len(file))\n",
    "    for word in doc_dict:\n",
    "        doc_dict[word] = doc_dict[word] / length\n",
    "    \n",
    "    return doc_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates a dictionary of the count of words appearing in all training data\n",
    "\n",
    "word_count = {}\n",
    "\n",
    "for x in Xtrain:\n",
    "    dic = tf(x)\n",
    "    for word in dic:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# returns amount of times word occurs in all files in training data\n",
    "def count(term):\n",
    "    if term not in word_count:\n",
    "        return 1\n",
    "    return word_count[term]\n",
    "\n",
    "# takes document dictionary and creates tfidf dictionary from it\n",
    "def idf(doc_dic):\n",
    "    new = {}\n",
    "    for word in doc_dic:\n",
    "        new[word] = doc_dic[word]*math.log(len(Xtrain)/count(word))\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates a all encompassing dictionary for all news types.\n",
    "# each key is 0-19, the story types, and tfidf values\n",
    "\n",
    "def classify():\n",
    "    final = {}\n",
    "    for x in range(20):\n",
    "        final[x] = {}\n",
    "    for x in range(len(Xtrain)):\n",
    "        doc_dict = idf(tf(Xtrain[x]))\n",
    "        \n",
    "        for key in final[Ctrain[x]]:\n",
    "            if key in doc_dict:\n",
    "                final[Ctrain[x]][key] *= doc_dict[key]\n",
    "\n",
    "        for key in doc_dict:\n",
    "            if key not in final[Ctrain[x]]:\n",
    "                final[Ctrain[x]][key] = doc_dict[key]\n",
    "\n",
    "    return final\n",
    "        \n",
    "final = classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# go through test data and make guesses for its news type\n",
    "\n",
    "guesses = []\n",
    "\n",
    "for doc in Xtest:\n",
    "\n",
    "    score = {}\n",
    "    doc_dic = idf(tf(doc))\n",
    "    for classes in final:\n",
    "        score[classes] = 0\n",
    "        for word in doc_dic:\n",
    "            if word in final[classes]:\n",
    "                score[classes] += 1\n",
    "                #score[classes] += final[classes][word]+doc_dic[word]\n",
    "\n",
    "\n",
    "    guesses.append(max(score, key=score.get))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.42629904559915 % of test data was identified correctly\n"
     ]
    }
   ],
   "source": [
    "# compares calculated guesses to true values\n",
    "# calculates accuracy of correctness\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "for x in range(len(Ctest)):\n",
    "    if Ctest[x] == guesses[x]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "print((correct/(correct+wrong))*100,\"% of test data was identified correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
